{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4lFhJ_rnGhJi"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.random import seed\n",
        "seed(42)\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(42)\n",
        "import random\n",
        "random.seed(42)"
      ],
      "metadata": {
        "id": "lm_IjULoGk8r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "WWZcoDD9GmHS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reading in csv\n",
        "file_path = '/content/drive/My Drive/DS340/CHD_men.csv'\n",
        "male_data = pd.read_csv(file_path, sep=\";\")\n",
        "\n",
        "male_data.head(10)"
      ],
      "metadata": {
        "id": "HrUiTV7OGnO5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building CNN model based off of CNN structure from paper 2\n",
        "# had to keep padding as \"same\" - does not match the paper\n",
        "# also changed from softmax to sigmoid, as sigmoid is better for binary classification\n",
        "def gender_model(hp):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Layer 1: Dense layer w/ 64 neurons, batch normalization, ReLU activation and dropout\n",
        "    # hyperparameter tuning ==> # of neurons\n",
        "    model.add(Dense(units = hp.Int('Dense1_neuonrs', min_value = 32, max_value = 512, step = 32),\n",
        "                    input_shape=(11, 1)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(ReLU())\n",
        "    model.add(Dropout(hp.Float('Dense1_dropout', min_value = 0.1, max_value = 0.5, step = 0.05)))\n",
        "\n",
        "\n",
        "    # Layer 2: Convolutional layer w/ 2 filters, kernel size of 4, no padding, 2 strides, Batch Normalization, ReLU and average pooling\n",
        "    model.add(Conv1D(filters=2,\n",
        "                     kernel_size= 4,\n",
        "                     strides = 2,\n",
        "                     padding = 'same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(ReLU())\n",
        "    #model.add(GlobalAveragePooling1D())\n",
        "\n",
        "\n",
        "    # Layer 3: Convolutional layer w/ 4 filters, kernel size of 4, no padding, 2 strides, Batch Normalization, ReLU and average pooling\n",
        "    model.add(Conv1D(filters=4,\n",
        "                     kernel_size = 6,\n",
        "                     strides = 2,\n",
        "                     padding = 'same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(ReLU())\n",
        "    #model.add(GlobalAveragePooling1D())\n",
        "\n",
        "    # had to add because of errors\n",
        "    model.add(Flatten())\n",
        "\n",
        "    # Layer 4: Dense layer with 512 neurons, Batch normalization, ReLU and dropout\n",
        "    # Hyperparameter tuning ==> # of neurons\n",
        "    model.add(Dense(units = hp.Int('Dense2_neurons', min_value = 32, max_value = 512, step = 32)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(ReLU())\n",
        "    model.add(Dropout(hp.Float('Dense2_dropout', min_value = 0.1, max_value = 0.5, step = 0.05)))\n",
        "\n",
        "    # Layer 5: Dense layer with 1 neuron\n",
        "    model.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "H481dtazHaZ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_male = male_data.drop(columns=['gender', 'cardio'])\n",
        "y_male = male_data['cardio']\n",
        "\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(X_male, y_male, test_size=0.2, random_state=42, stratify=y_male)\n",
        "\n",
        "# Split the training data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.25, random_state=42, stratify=y_train_full)"
      ],
      "metadata": {
        "id": "saBvd7e3HhGj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler_male = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_val = scaler.transform(X_val)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "BH_ZWCTwHiia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "X_val = X_val.reshape(X_val.shape[0], X_val.shape[1], 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)"
      ],
      "metadata": {
        "id": "lrsV-3lzHju0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate Keras Tuner\n",
        "tuner = RandomSearch(gender_model, objective='val_accuracy', max_trials=3, executions_per_trial=3,\n",
        "                          directory='./DS340_CHD', project_name='tuner_male')\n",
        "\n",
        "\n",
        "# Search for the best hyperparameters\n",
        "tuner.search(X_train, y_train, epochs=10, validation_data=(X_val, y_val))\n",
        "\n",
        "# Get the best model and evaluate on the test set\n",
        "best_model = tuner.get_best_models(num_models=1)[0]\n",
        "test_loss, test_acc = best_model.evaluate(X_test, y_test)\n",
        "print(f'Test Loss (after tuning): {test_loss}, Test Accuracy (after tuning): {test_acc}')"
      ],
      "metadata": {
        "id": "re3WR1CbHk1M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_best_model():\n",
        "    model = tuner.hypermodel.build(best_hps)\n",
        "    return model\n",
        "\n",
        "model = KerasClassifier(build_fn=build_best_model, epochs=20, batch_size=32, verbose=0)\n",
        "\n",
        "# Now fit the bagging model\n",
        "bagging_model = BaggingClassifier(estimator=model, n_estimators=10, random_state=42)\n",
        "# Flatten X_train for the BaggingClassifier\n",
        "X_train_flat = X_train.reshape(X_train.shape[0], -1)\n",
        "\n",
        "# Fit bagging with flattened data\n",
        "bagging_model.fit(X_train_flat, y_train)"
      ],
      "metadata": {
        "id": "bpbyPxYRHmYk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 8: Evaluate the model on the test set\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred = bagging_model.predict(X_test.reshape(X_test.shape[0], -1))  # Reshape X_test if needed\n",
        "\n",
        "# Calculate accuracy\n",
        "test_acc = accuracy_score(y_test, y_pred)\n",
        "print(f'Test Accuracy: {test_acc}')"
      ],
      "metadata": {
        "id": "t1exPJLHHnWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "X_train_sample = shap.sample(X_train, 50)\n",
        "X_test_sample = shap.sample(X_test, 50)"
      ],
      "metadata": {
        "id": "fpi7zyPWHn5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_reshaped = X_train_sample.reshape(X_train_sample.shape[0], -1)\n",
        "X_test_reshaped = X_test_sample.reshape(X_test_sample.shape[0], -1)"
      ],
      "metadata": {
        "id": "zSTqVC8NImLQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import os\n",
        "\n",
        "drive_path = '/content/drive/My Drive/DS340/'  # Replace with your folder name\n",
        "explainer_file = os.path.join(drive_path, 'shap_explainer_males.pkl')\n",
        "\n",
        "\n",
        "if os.path.exists(explainer_file):\n",
        "  explainer = joblib.load(explainer_file)\n",
        "else:\n",
        "  # Create SHAP explainer\n",
        "  explainer = shap.KernelExplainer(bagging_model.predict, X_train_reshaped,approximate = True)\n",
        "\n",
        "  # Calculate SHAP values (this might take some time)\n",
        "  shap_values = explainer.shap_values(X_test_reshaped)\n",
        "\n",
        "  # saving explainer to google drive\n",
        "  joblib.dump(explainer, explainer_file)"
      ],
      "metadata": {
        "id": "X0AQ5qwbInuX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_names = ['age', 'height', 'weight', 'sys_bp', 'dia_bp', 'cholesterol', 'gluc', 'smoke', 'alco', 'active']\n",
        "shap.summary_plot(shap_values, X_test_reshaped, feature_names=feature_names, plot_type='bar')"
      ],
      "metadata": {
        "id": "jBfxtqBwIo5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap.waterfall_plot(shap.Explanation(values=shap_values[0], base_values=explainer.expected_value, data=X_test_reshaped[0], feature_names=feature_names))"
      ],
      "metadata": {
        "id": "v0kw0uzHItH4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap.decision_plot(explainer.expected_value, shap_values[0], X_test_reshaped, feature_names=feature_names)"
      ],
      "metadata": {
        "id": "l08qtAOJIub4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lime\n",
        "from lime.lime_tabular import LimeTabularExplainer"
      ],
      "metadata": {
        "id": "-0xL976kIvvg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# doing LIME for first 10 test instances\n",
        "test_instance = X_test_reshaped[0]  # First test sample\n",
        "\n",
        "# Generate explanation for the prediction\n",
        "explanation = lime_explainer.explain_instance(\n",
        "    data_row=test_instance,\n",
        "    predict_fn=bagging_model.predict_proba  # Function to predict probabilities\n",
        ")\n",
        "\n",
        "explanation.show_in_notebook(show_table=True)"
      ],
      "metadata": {
        "id": "28Fbn10TIw9e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# doing LIME for first 10 test instances\n",
        "test_instance = X_test_reshaped[10]  # First test sample\n",
        "\n",
        "# Generate explanation for the prediction\n",
        "explanation = lime_explainer.explain_instance(\n",
        "    data_row=test_instance,\n",
        "    predict_fn=bagging_model.predict_proba  # Function to predict probabilities\n",
        ")\n",
        "\n",
        "explanation.show_in_notebook(show_table=True)"
      ],
      "metadata": {
        "id": "6q7aWiNaIyKk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}